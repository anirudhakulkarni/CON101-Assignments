\documentclass{article}
\usepackage[utf8]{inputenc}
	\addtolength{\oddsidemargin}{-.875in}
		\addtolength{\textheight}{0.5in}
\usepackage{graphicx}
\usepackage[table,xcdraw]{xcolor}
\usepackage{amsmath}
\title{CON101 : Ethics issue in AI}
\author{Anirudha Kulkarni}
\date{October 2020}
\usepackage{graphics}
\usepackage{hyperref}
\usepackage[export]{adjustbox}
\usepackage[table,xcdraw]{xcolor}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\begin{document}

\maketitle
\section{Introduction}
The AI has opened a new world of opportunities. Many people are working to make world “a better place”. However, problems with AI like biases, low level explanation of learning, manipulation of data and practically infinite power is posing some serious ethical challenges. Some of the important issues are discussed below.
\section{Ethics issue}
\begin{itemize}
    \item Artificial intelligence have potential to replace many jobs. Most of the companies still depend upon the amount of hours spent by employee in office. AI will affect it drastically. It can work for practically infinite amount of time provided enough resources. The maintenance cost for such CPUs is much less than that of a person paid for similar work. Such drastic reduction of workers will reduce the amount of money to be paid to the employees. Such reduction will cause the large portion of profits to be centred around handful of founders and engineers. Its terrible for economy. So in a way to make life easier we are making lives more miserable. It will further expand the inequality.
\item AI can get many biases  while learning and implementation. Having datasets with some history biases the whole algorithm. Amazon’s recruiting model falls in this category. Amazon had to shut down its AI based model to shortlist candidates for recruiting after it started to show bias towards male candidates. It happened due to previous trends in tech jobs. Tech industry had male domination in past. Another example is with future criminal predicting model. It showed high bias towards black people.   software used to predict future criminals. AI systems are created by humans with lots of biases and judgements. And such biases if not attended can affect some portion of society in negative way. Being racist is the issue AI. 

\item One another ethical issue with AI is use of information to manipulate feelings and behaviour. Human mind do not have enough computational resources to compete with machines in term of raw processing power. Using AI in affecting rational choices to ones benefits is not at all ethical. It’s a way to exploit someone’s lack of knowledge for personal gains. It can be compared with enslaving by people in power. Even though a product is not worthy of choice it can get importance on basis of manipulation by AI. This shall too lead to inequality of competition.
\item Opaque: AI systems work on feedback mechanism on dataset. If machine predicts it correctly it gets rewarded else its parameters are modified. But even the person who implements it don’t know how exactly machine is learning. Most of the learning is happening at backend. Such learning can be dangerous to humans. It might learn something that is not in our best interest or even harm us.
\item Most of advertisement use AI to predict designs to optimize chances of clicking on it. Games are too evolving with it too make it more addictive. For such predictions the data is collected from a persons digital footprint. Which is in a way exploiting people in name of free service but charging them in terms of data. 
\end{itemize}
\section{Summary}
Ethical considerations are major part of any policy related to AI. Many governments are starting to take such issues seriously. Singapore recently created Ethics council on AI. It need to be regulated to avoid sensitive issues like human rights violation and mass surveillance. Such steps will surely make world “a fairer place” along with better place to everyone
\section{References}
\begin{itemize}
    \item Racial disparities in automated speech recognition. URL: \url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7149386/}
    \item Machine Bias. URL: \url{https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing}
    \item Amazon scraps secret AI recruiting tool that showed bias against women. URL: \url{https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G}
\end{itemize}
\end{document}